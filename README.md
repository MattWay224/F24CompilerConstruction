# F24CompilerConstruction
### Our team:
- **Matthew Rusakov:** Responsible for writing the compiler code and testing it based on previously written tests.
- **Aliia Bogapova:** Responsible for writing the compiler code and testing it based on previously written tests.
- **Polina Pushkareva:** Responsible for organizational aspects, presentations, and reports.

### Project Overview:
**Project-F:** 

The goal of this project is to develop an interpreter for a Lisp-like functional programming language. The project will be completed in several stages, starting with lexical analysis and progressing through syntax analysis, semantic analysis, and finally code interpretation.

**Technologies Used:** 

- *Language:* Java
- *Lexer:* Handwritten lexer
- *Parser:* Handwritten parser

**Project stages:**

The project will be implemented in four stages:

1. Lexical Analyzer (Lexer)
2. Syntax Analyzer (Parser)
3. Semantic Analyzer
4. Code Interpretation

### 1. *Lexical Analyser:*

**Purpose:**

The lexical analyzer (also called the "lexer" or "tokenizer") reads the input code and breaks it down into tokens. Tokens are the smallest units of meaning in the code, such as parentheses, operators, keywords, numbers, and literals. The lexical analyzer is responsible for recognizing these tokens and categorizing them into different types.

**Technical Details:**

Class: ```Flexer```

The ```Flexer``` class is responsible for implementing the lexical analyzer in Java. It takes the input source code, processes it character by character, and generates a sequence of tokens.

Inner Class: ```Token```

The ```Token``` class represents a single token, which contains:

- *type*: The type of the token (e.g., keyword, operator, literal, etc.).
- *value*: The actual content of the token (e.g., +, 42, true, etc.).

Ennumeration: ```TokenType```

We use an enumeration called ```TokenType``` to classify various token types. Some of the primary token types in our language are:

- *Parentheses*: Open ```(``` and close ```)```.
- *Keywords*: Reserved words in the language like ```func```, ```cond```, ```while```, ```lambda```, etc.
- *Operators*: Arithmetic and logical operators like ```+```, ```-```, ```*```, ```/```, ```and```, ```or```.
- *Literals*: Constants like numbers: integers and reals (```42```, ```3.14```) and booleans (```true```, ``false``).
- *Quoted Expressions*: Expressions starting with a single quote, such as ```'expr```.

Key Methods in Flexer:

- ```tokenize()```: This is the main method that takes the input string and processes it to generate a list of tokens. It handles the breakdown of the input code by analyzing each character and determining whether it forms part of a token.
- ```parseNumber()```: This method identifies and processes numeric values (integers and real numbers) in the input.
- ```parseIdOrKeyword()```: This method processes identifiers, which can be function names, function names, or keywords.
- *Error Handling*: The lexical analyzer also includes mechanisms for identifying and handling invalid tokens. If an unknown character or sequence is encountered, an error is thrown.

### 2. *Syntax Analyser*

**Purpose:**

The syntax analyzer, or parser, takes the sequence of tokens generated by the lexical analyzer and constructs an Abstract Syntax Tree (AST). The AST represents the hierarchical structure of the source code, capturing the relationships between language constructs like functions, variables, and expressions. The parser checks whether the token sequence follows the correct syntax rules of the  F-language, ensuring the code is grammatically correct.

**Technical Details:**

*Parsing Approach:*

We use top-down parsing to build the AST, starting from the highest-level grammar rules and breaking them down into smaller components. The parser traverses the token sequence and recursively parses each construct, creating corresponding nodes in the AST.

*Abstract Syntax Tree (AST):*

- *Nodes:* Each AST node represents a syntactic structure in the source code, such as a function definition, an arithmetic operation, or a conditional statement.
- *Composite Pattern:* We apply the *Composite Pattern* to manage complex AST structures, where certain nodes (e.g., high-order function nodes) can have multiple child nodes, representing nested expressions or function arguments.
- *Factory Pattern:* A *Factory* is used to generate different types of AST nodes, ensuring clean and modular node creation.

*Symbol Table:*

The parser maintains a symbol table that stores information about each declared entity (such as variables, functions, and constants). For each entity, the symbol table records:

- *Name:* The identifier used in the source code.
- *Value:* The current value or expression associated with the entity.
- *Span:* The range of source code covered by the entity (start and end positions).
- *Extra Info:* Metadata like the line number, which is used for debugging and error reporting.

*Design Patterns:*

- *Singleton Pattern:* Large components like the Lexer, Parser, and Factory are implemented as Singletons to ensure that only one instance of each class is active at a time, preventing duplication and maintaining global state.
- *Factory Pattern:* The *Factory Pattern* is applied for creating AST nodes, simplifying the process of generating various node types (e.g., function nodes, operation nodes, and conditional nodes).
- *Visitor Pattern:* We use the *Visitor Pattern* for traversing and processing the AST. This pattern is particularly useful for exporting the tree structure to external formats like text files, facilitating AST visualization and debugging.
- *Composite Pattern:* The *Composite Pattern* allows for flexible and hierarchical organization of AST nodes. For instance, high-order functions, which take other functions as arguments, are treated as composite nodes that may contain multiple child nodes.

### 3. *Semantic Analyser*

To be written after this stage is implemented.

### 4. *Code Interpretation*

To be written after this stage is implemented.

### Future Work

- *Semantic analysis*, which will check the correctness of the code in terms of types, scopes, and function definitions.
- *Code interpretation*, where the program will evaluate and run the functional language code.
